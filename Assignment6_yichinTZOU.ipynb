{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5afa76",
   "metadata": {},
   "source": [
    "## Assignment 6 - Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e07e07",
   "metadata": {},
   "source": [
    "by:Yichin Tzou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72cd3d",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network & Classification: \n",
    "\n",
    "The objective is to build an image classifier that is capable of properly identifying four different categories of image. \n",
    "\n",
    "The data consists of various train and test samples across the four categories of image. You will notice that the data for a specific category is a singular image that has been flipped, rotated, or slightly altered in some way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f61e2d",
   "metadata": {},
   "source": [
    "### Preparation \n",
    "1.First Install TensorFlow with Python's pip package manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda9dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (23.1.2)\n",
      "Requirement already satisfied: tensorflow in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.7.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jasmine19970120/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Requires the latest pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d28ac7",
   "metadata": {},
   "source": [
    "### 2.Setup/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92041b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:25.079984: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93baa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import os, glob\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3181ad",
   "metadata": {},
   "source": [
    "## 1. Data Processing: \n",
    "\n",
    "The train & test data is pretty clean in terms of image data, but we will need to do a bit of prep work to use in our model. \n",
    "\n",
    "### a) Use the \"ImageDataGenerator()\" class from keras.processing.image to build out an instance called \"train_datagen\" with the following parameters: \n",
    "\n",
    "- rescale = 1./255\n",
    "- shear_range = 0.2\n",
    "- zoom_range = 0.2\n",
    "- horizontal_flip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9574c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e596e",
   "metadata": {},
   "source": [
    "### b) Then build your training set by using the method \".flow_from_directory()\"\n",
    "\n",
    "- path (where training data is stored)\n",
    "- target_size = (64, 64)\n",
    "- batch_size = 32\n",
    "- class_mode = categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99f5917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset_train',  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe8262a",
   "metadata": {},
   "source": [
    "### c) Take a look at your training set: \n",
    "\n",
    "What is the image shape of each training observation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6231bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = train_generator.image_shape\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227db75",
   "metadata": {},
   "source": [
    "How many total classes do we need to predict on? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a880450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_classes = train_generator.num_classes\n",
    "total_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85064fb",
   "metadata": {},
   "source": [
    "## 2. Initial Classifier Build: \n",
    "\n",
    "Now use keras to build an initial image classifier with the following specifications.\n",
    "\n",
    "Note: If you get lost, there is great documentation online and homework 7 included details on many of the layers used here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4befa976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Sequential\n",
    "classifier = Sequential()\n",
    "\n",
    "# Add a Conv2D layer\n",
    "classifier.add(Conv2D(32, kernel_size=(3, 3), input_shape=image_shape, activation='relu'))\n",
    "\n",
    "# Add a MaxPooling2D layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add another Conv2D layer\n",
    "classifier.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling2D layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a Flatten layer\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Add a Dense layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add a final Dense layer\n",
    "classifier.add(Dense(units=total_classes, activation='softmax'))\n",
    "\n",
    "# Compile the classifier\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb7543",
   "metadata": {},
   "source": [
    "## 3. Model Runs: \n",
    "\n",
    "This will be run various times with different numbers of steps_per_epoch and epochs. \n",
    "\n",
    "### a) Use .fit() with the training set. For the first run, use the following parameters: \n",
    "\n",
    "- steps_per_epoch = 3\n",
    "- epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d62c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:32.391401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 230ms/step - loss: 1.7888 - accuracy: 0.2273\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 1.0822 - accuracy: 0.5682\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.7783 - accuracy: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd331716640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=3,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b17eb",
   "metadata": {},
   "source": [
    "### b) save model to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24604752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "classifier.save('my_model.h5')\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4bc9f",
   "metadata": {},
   "source": [
    "### c) Predict using the model built in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34df8063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "dataset_test/C033.png\n",
      "dataset_test/1022.png\n",
      "dataset_test/4011.png\n",
      "dataset_test/1053.png\n",
      "dataset_test/6051.png\n",
      "dataset_test/4053.png\n",
      "dataset_test/C014.png\n",
      "dataset_test/6023.png\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# test data path\n",
    "img_dir = \"dataset_test\" # Enter Directory of test set\n",
    "\n",
    "# iterate over each test image\n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "\n",
    "# print the files in the dataset_test folder \n",
    "for f in files:\n",
    "    print(f)\n",
    "    \n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253acea",
   "metadata": {},
   "source": [
    "### d) Determine accuracy.\n",
    "\n",
    "Note: To determine accuracy, you will need to check the labels given to each class in the training data and manually label your test data. This will require you to look into the training data(images) in the dataset_train folder, and then determine how a category was coded in keras.\n",
    "\n",
    "- Look into the training data(images) in the dataset_train folder, and then determine how a category was coded in keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31217bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category 1': 0, 'category 2': 1, 'category 3': 2, 'category 4': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check category labels in training_set\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed81a4",
   "metadata": {},
   "source": [
    "- look in the test data(images) in the dataset_test folder, and identify what category each images belongs to using images in the training set as references(there are only 8 test observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda4382",
   "metadata": {},
   "source": [
    "- Create a list to store the category/labels for the test data as the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fb1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label= [3, 0, 2, 0, 1, 2, 3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867f33e",
   "metadata": {},
   "source": [
    "- Compare the predicted values to the actual values for the test set and calculate accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8322a3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_label, results)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194a6be",
   "metadata": {},
   "source": [
    "### e) Run this process for the following combinations:\n",
    "\n",
    "* (steps_per_epoch: 1, epochs: 1)\n",
    "* (steps_per_epoch: 1, epochs: 2)\n",
    "* (steps_per_epoch: 1, epochs: 3)\n",
    "* (steps_per_epoch: 2, epochs: 4)\n",
    "* (steps_per_epoch: 2, epochs: 5)\n",
    "* (steps_per_epoch: 2, epochs: 6)\n",
    "* (steps_per_epoch: 3, epochs: 7)\n",
    "* (steps_per_epoch: 3, epochs: 8)\n",
    "* (steps_per_epoch: 5, epochs: 9)\n",
    "* (steps_per_epoch: 5, epochs: 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da04ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = [1,1,1, 2,2,2, 3,3, 5,5]\n",
    "epochs =list(np.arange(10)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1e494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:36.704328: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 922ms/step - loss: 1.4550 - accuracy: 0.2500\n",
      "Saved model my_model_1.h5\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:38.098731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 822ms/step - loss: 1.4073 - accuracy: 0.0417\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.3811 - accuracy: 0.5625\n",
      "Saved model my_model_2.h5\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:39.939638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 857ms/step - loss: 1.4694 - accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.8963 - accuracy: 0.2500\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.1130 - accuracy: 0.6562\n",
      "Saved model my_model_3.h5\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:42.437302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fd3209d9d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.6554 - accuracy: 0.2500\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 1s 194ms/step - loss: 1.2220 - accuracy: 0.5179\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 1.0024 - accuracy: 0.6607\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 1s 262ms/step - loss: 0.7877 - accuracy: 0.7344\n",
      "Saved model my_model_4.h5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:46.430819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 266ms/step - loss: 1.5553 - accuracy: 0.1875\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 1.2000 - accuracy: 0.5714\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.9464 - accuracy: 0.6786\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.5486 - accuracy: 0.9286\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.4569 - accuracy: 0.9062\n",
      "Saved model my_model_5.h5\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:50.925339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 256ms/step - loss: 1.5228 - accuracy: 0.3571\n",
      "Epoch 2/6\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 1.2086 - accuracy: 0.4464\n",
      "Epoch 3/6\n",
      "2/2 [==============================] - 1s 259ms/step - loss: 0.7413 - accuracy: 0.7656\n",
      "Epoch 4/6\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 5/6\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.3369 - accuracy: 0.9107\n",
      "Epoch 6/6\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 0.2847 - accuracy: 0.9219\n",
      "Saved model my_model_6.h5\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:51:55.936598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 262ms/step - loss: 1.1710 - accuracy: 0.4545\n",
      "Epoch 2/7\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.8844 - accuracy: 0.6932\n",
      "Epoch 3/7\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 0.4366 - accuracy: 0.8977\n",
      "Epoch 4/7\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.2456 - accuracy: 0.9432\n",
      "Epoch 5/7\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 0.2475 - accuracy: 0.9205\n",
      "Epoch 6/7\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 0.1650 - accuracy: 0.9545\n",
      "Epoch 7/7\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 0.1210 - accuracy: 0.9659\n",
      "Saved model my_model_7.h5\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:52:02.721769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 230ms/step - loss: 2.3679 - accuracy: 0.2273\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 1.0982 - accuracy: 0.5568\n",
      "Epoch 3/8\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.7049 - accuracy: 0.7841\n",
      "Epoch 4/8\n",
      "3/3 [==============================] - 1s 265ms/step - loss: 0.5718 - accuracy: 0.8636\n",
      "Epoch 5/8\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 0.3386 - accuracy: 0.9432\n",
      "Epoch 6/8\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.2400 - accuracy: 0.9773\n",
      "Epoch 7/8\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1682 - accuracy: 0.9432\n",
      "Epoch 8/8\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.2224 - accuracy: 0.9205\n",
      "Saved model my_model_8.h5\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:52:09.871089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 [=================>............] - ETA: 0s - loss: 1.4836 - accuracy: 0.3295WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 45 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 2s 209ms/step - loss: 1.4836 - accuracy: 0.3295\n",
      "Saved model my_model_9.h5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:52:11.946747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 [=================>............] - ETA: 0s - loss: 2.4269 - accuracy: 0.3295WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 2.4269 - accuracy: 0.3295\n",
      "Saved model my_model_10.h5\n"
     ]
    }
   ],
   "source": [
    "#run all the models from the above given combination\n",
    "for i, j in list(zip(steps_per_epoch, epochs)):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape =  (64, 64,3),activation = \"relu\"))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    classifier.add(Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\"))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "    classifier.add(Dense(units = 4, activation = \"softmax\"))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    classifier.fit(train_generator,steps_per_epoch = i, epochs=j)\n",
    "    name = \"my_model_\" + str(j) + \".h5\"\n",
    "    classifier.save(name)\n",
    "    print(f\"Saved model {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b01d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for j in (np.arange(10)+1):\n",
    "    name = \"my_model_\" + str(j) + \".h5\"\n",
    "    # returns a compiled model\n",
    "    # identical to the previous one\n",
    "    model = load_model(name)\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # make a prediction and add to results \n",
    "    data = []\n",
    "    results = []\n",
    "    for f1 in files:\n",
    "        img = image.load_img(f1, target_size = (64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        data.append(img)\n",
    "        result = model.predict(img)\n",
    "        r = np.argmax(result, axis=1)\n",
    "        results.append(r)\n",
    "        \n",
    "    score = accuracy_score(test_label,results)\n",
    "    accuracy_list.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b71a28",
   "metadata": {},
   "source": [
    "### f) Create a final dataframe that combines the accuracy across each combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef34ab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps per Epoch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Steps per Epoch  Epochs  Accuracy\n",
       "0                1       1     0.250\n",
       "1                1       2     0.750\n",
       "2                1       3     0.625\n",
       "3                2       4     0.875\n",
       "4                2       5     0.875\n",
       "5                2       6     0.875\n",
       "6                3       7     0.750\n",
       "7                3       8     0.875\n",
       "8                5       9     0.625\n",
       "9                5      10     0.250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy = pd.DataFrame(list(zip(steps_per_epoch, epochs, accuracy_list)), columns=['Steps per Epoch', 'Epochs','Accuracy'])\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30e910",
   "metadata": {},
   "source": [
    "## Conceptual Questions: \n",
    "\n",
    "## 4. Discuss the effect of the following on accuracy and loss (train & test): \n",
    "\n",
    "### - Increasing the steps_per_epoch\n",
    "\n",
    "Increasing the steps_per_epoch means that more training samples will be processed within each epoch. This can potentially lead to better accuracy and reduce the loss during training, since the model can see and learn from more data during each epoch. However, \n",
    "\n",
    "### - Increasing the number of epochs\n",
    "\n",
    "Increasing the number of epochs allows the model to see the entire training dataset multiple times. This can help improve accuracy and reduce the loss during training, by giving the model more opportunities to learn and refine its predictions. However, if the model starts to overfit the training data, increasing the number of epochs beyond a certain point can lead to a decrease in accuracy on unseen test data.\n",
    "\n",
    "\n",
    "\n",
    "## 5. Name two uses of zero padding in CNN.\n",
    "1. Keeping feature map size consistent: output feature map has the same dimensions as the input image\n",
    "2. Reducing the border effect: helps maintaining consistent information across the entire input and output volumes, preventing information loss at the edges.\n",
    "\n",
    "## 6. What is the use of a 1 x 1 kernel in CNN? \n",
    "The use of 1*1 kernal is to change the number of output feature maps\n",
    "\n",
    "## 7. What are the advantages of a CNN over a fully connected DNN for this image classification problem?\n",
    "1. Fewer parameters: A CNN has fewer parameters than a fully connected DNN, which makes it much faster to train, reduces the risk of overfitting, and requires much less training data.\n",
    "\n",
    "2. Computational Efficiency: Due to parameter sharing and the localized nature of convolutions, CNNs are computationally more efficient compared to fully connected DNNs when dealing with high-dimensional input data such as images. CNNs leverage the convolutional operation, which reduces the number of parameters and the computational cost by reusing weights in different spatial locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
